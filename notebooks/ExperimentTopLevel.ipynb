{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import reuters\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "import wk\n",
    "from sklearn.metrics import accuracy_score\n",
    "import plotly.plotly as py\n",
    "from plotly.tools import FigureFactory as FF \n",
    "\n",
    "EARN = 0\n",
    "ACQ = 1\n",
    "CRUDE = 2\n",
    "CORN = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing train + test data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "\n",
    "print \"importing train + test data...\"\n",
    "all_files = reuters.fileids()\n",
    "#print(len(all_files))\n",
    "\n",
    "train_files = list(filter(lambda file: file.startswith('train'), all_files))\n",
    "#print(len(train_files))\n",
    "\n",
    "test_files = list(filter(lambda file: file.startswith('test'), all_files))\n",
    "#print(len(test_files))\n",
    "\n",
    "categories = reuters.categories()\n",
    "\n",
    "earn_docs = reuters.fileids('earn')\n",
    "acq_docs = reuters.fileids('acq')\n",
    "crude_docs = reuters.fileids('crude')\n",
    "corn_docs = reuters.fileids('corn')\n",
    "\n",
    "earn_train_docs = [w for w in earn_docs if w in train_files]   \n",
    "earn_test_docs = [w for w in earn_docs if w in test_files]  \n",
    "\n",
    "acq_train_docs = [w for w in acq_docs if w in train_files]   \n",
    "acq_test_docs = [w for w in acq_docs if w in test_files]  \n",
    "\n",
    "crude_train_docs = [w for w in crude_docs if w in train_files]   \n",
    "crude_test_docs = [w for w in crude_docs if w in test_files]  \n",
    "\n",
    "corn_train_docs = [w for w in corn_docs if w in train_files]   \n",
    "corn_test_docs = [w for w in corn_docs if w in test_files]  \n",
    "\n",
    "TrainDocVals = []\n",
    "TrainDocLabels = []\n",
    "TestDocVals = []\n",
    "TestDocLabels = []\n",
    "\n",
    "for docHandle in earn_train_docs[0:10]:\n",
    "    TrainDocVals.append(\" \".join(word_tokenize(reuters.raw(docHandle))))\n",
    "    TrainDocLabels.append(EARN)\n",
    "    \n",
    "for docHandle in acq_train_docs[0:10]:\n",
    "    TrainDocVals.append(\" \".join(word_tokenize(reuters.raw(docHandle))))\n",
    "    TrainDocLabels.append(ACQ)\n",
    "    \n",
    "for docHandle in crude_train_docs[0:10]:\n",
    "    TrainDocVals.append(\" \".join(word_tokenize(reuters.raw(docHandle))))\n",
    "    TrainDocLabels.append(CRUDE)\n",
    "    \n",
    "for docHandle in corn_train_docs[0:10]:\n",
    "    TrainDocVals.append(\" \".join(word_tokenize(reuters.raw(docHandle))))\n",
    "    TrainDocLabels.append(CORN)\n",
    "    \n",
    "for docHandle in earn_test_docs[0:10]:\n",
    "    TestDocVals.append(\" \".join(word_tokenize(reuters.raw(docHandle))))\n",
    "    TestDocLabels.append(EARN)\n",
    "    \n",
    "for docHandle in acq_test_docs[0:10]:\n",
    "    TestDocVals.append(\" \".join(word_tokenize(reuters.raw(docHandle))))\n",
    "    TestDocLabels.append(ACQ)\n",
    "    \n",
    "for docHandle in crude_test_docs[0:10]:\n",
    "    TestDocVals.append(\" \".join(word_tokenize(reuters.raw(docHandle))))\n",
    "    TestDocLabels.append(CRUDE)\n",
    "    \n",
    "for docHandle in corn_test_docs[0:10]:\n",
    "    TestDocVals.append(\" \".join(word_tokenize(reuters.raw(docHandle))))\n",
    "    TestDocLabels.append(CORN)\n",
    "    \n",
    "print \"done\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing WK gram matrix\n",
      "row 10 of 40\n",
      "\n",
      "row 20 of 40\n",
      "\n",
      "row 30 of 40\n",
      "\n",
      "row 40 of 40\n",
      "\n",
      "row 10 of 40\n",
      "\n",
      "row 20 of 40\n",
      "\n",
      "row 30 of 40\n",
      "\n",
      "row 40 of 40\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print \"computing WK gram matrix\"\n",
    "WKTestGram = np.ones((len(TestDocVals),len(TestDocVals)))\n",
    "WKTrainGram = np.ones((len(TrainDocVals),len(TrainDocVals)))\n",
    "for i in xrange( 0, len(TrainDocVals) ):\n",
    "    if( (i+1)%10 == 0 ):\n",
    "        print \"row %d of %d\\n\" % ( i+1, len(TrainDocVals) )       \n",
    "    for j in xrange(0,len(TrainDocVals)):\n",
    "        WKTrainGram[i][j] = wk.wk(TrainDocVals[i], TrainDocVals[j])\n",
    "        \n",
    "for i in xrange( 0, len(TestDocVals) ):\n",
    "    if( (i+1)%10 == 0 ):\n",
    "        print \"row %d of %d\\n\" % ( i+1, len(TestDocVals) )       \n",
    "    for j in xrange(0,len(TestDocVals)):\n",
    "        WKTestGram[i][j] = wk.wk(TestDocVals[i], TestDocVals[j])\n",
    "        \n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:\n",
      "[ 1.          0.83333333  1.          1.        ]\n",
      "recall:\n",
      "[ 0.9  1.   0.9  1. ]\n",
      "F1: \n",
      "[ 0.94736842  0.90909091  0.94736842  1.        ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~jmanttari/14.embed\" height=\"200px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='precomputed')\n",
    "\n",
    "clf.fit(WKTrainGram, TrainDocLabels)\n",
    "label_pred = clf.predict(WKTestGram)\n",
    "\n",
    "\n",
    " \n",
    "precision, recall, fscore, support = metrics.precision_recall_fscore_support(TestDocLabels, label_pred)\n",
    "\n",
    "print \"Precision:\"\n",
    "print precision\n",
    "print \"recall:\" \n",
    "print recall\n",
    "print \"F1: \"\n",
    "print fscore\n",
    "\n",
    "#print_results_table(precision,recall,fscore)\n",
    "\n",
    "data_matrix = [['Label', 'F1 Score', 'Precision', 'Recall'],\n",
    "                   ['Earn', fscore[EARN],precision[EARN],recall[EARN]],\n",
    "                   ['ACQ', fscore[ACQ],precision[ACQ],recall[ACQ]],\n",
    "                   ['CRUDE', fscore[CRUDE],precision[CRUDE],recall[CRUDE]],\n",
    "                   ['CORN', fscore[CORN],precision[CORN],recall[CORN]]]\n",
    "\n",
    "table = FF.create_table(data_matrix)\n",
    "py.iplot(table, filename='F1 Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
